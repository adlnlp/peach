{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO9XS8VRZ3/PqTrf9jYOvI4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# load precomputed embedding"],"metadata":{"id":"Hp-4fqeRWjyC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xBpPAGVPqN7"},"outputs":[],"source":["import pandas as pd\n","def load_features(train_path, test_path):\n","    \"\"\"\n","    Load precomputed features/embeddings for training and testing\n","\n","    Args:\n","        train_path (str): where the training corpus features (after dimension reduction) is saved. Each row contains the precomputed features and the ground truth class label for one document.\n","        test_path (str): where the testing corpus features (after dimension reduction) is saved. Each row contains the precomputed features and the ground truth class label for one document.\n","\n","    Returns:\n","        df (Dataframe): training corpus features\n","        df_test (Dataframe): testing corpus features\n","    \"\"\"\n","    df = pd.read_csv(train_path,sep=',')\n","    df['Class_label'] = df['Class_label'].astype(str)\n","\n","    df_test = pd.read_csv(test_path,sep=',')\n","    df_test['Class_label'] = df_test['Class_label'].astype(str)\n","\n","    return df, df_test"]},{"cell_type":"markdown","source":["# Overall grouping function (TODO)"],"metadata":{"id":"3ts_LXc5Wo_j"}},{"cell_type":"markdown","source":["# Correlation construction, grouping, and store features\n"],"metadata":{"id":"giAycor0WyY0"}},{"cell_type":"code","source":["def correlation_grouping(df,df_test, output_path_prefix, correlation_type = 'pearson', threshold_quantile = 0.9, save_csv=True):\n","    \"\"\"\n","    Group and merge training and testing features based on correlation between the dimensions.\n","\n","    Args:\n","        df (Dataframe): training corpus features\n","        df_test (Dataframe): testing corpus features\n","        output_path_prefix (str): prefix to the file path where the output files will be saved.\n","        correlation_type (str): method to calculate correlation among the columns. Available options are ['pearson', 'kendall', 'biserial']. Note that 'biserial' can only be applied to binary dataset. Default as 'pearson'.\n","        threshold_quantile (float): a threshold to define highly correlated dimensions to merge them. Default as 0.9.\n","        save_csv (bool): whether to save the output csv files. Default as True.\n","\n","\n","    Returns:\n","        group_feats_df_train (Dataframe): training corpus features after merging\n","        group_feats_df_test (Dataframe): testing corpus features after merging\n","    \"\"\"\n","\n","    assert correlation_type in ['pearson', 'kendall', 'biserial']\n","\n","    if correlation_type == 'biserial':\n","        try:\n","            no_feats = len(df.columns)-1\n","            X_train = df.iloc[:,:no_feats]\n","            y_train = df.iloc[:,no_feats]\n","            corr_df = X_train.corrwith(y_train,axis=0)\n","            flatten_corr_df = corr_df\n","        except:\n","            print(\"Input data must be binary dataset for using point biserial correlation. Please try another compatible correlation method.\")\n","    else:\n","        corr_df = df.corr(method=correlation_type)\n","        flatten_corr_df = corr_df.stack()\n","        threshold = flatten_corr_df.quantile(threshold_quantile)\n","        corr_df_tf = corr_df >= threshold\n","        num_of_related_feats = (corr_df > threshold).sum(axis=1)\n","\n","        merge_groups = {}\n","        for i in corr_df_tf.index:\n","            for j in corr_df_tf.columns:\n","                if corr_df_tf.loc[i,j] == True:\n","                    try:\n","                        merge_groups[i].append(j)\n","                    except:\n","                        merge_groups[i] = [j]\n","\n","\n","        updated_groups = {}\n","        dims_included = []\n","        for key,val in merge_groups.items():\n","            if key in dims_included:\n","                continue\n","            else:\n","                updated_groups[key] = val\n","                dims_included.extend(val)\n","                dims_included = list(set(dims_included))\n","\n","        new_column_names = list(updated_groups.keys()) + ['Class_label']\n","        group_feats_df_train = df.loc[:,new_column_names]\n","        for key,val in updated_groups.items():\n","            group_feats_df_train.loc[:,key]  = df.loc[:,val].mean(axis='columns')\n","        group_feats_df_test = df_test.loc[:,new_column_names]\n","        for key,val in updated_groups.items():\n","            group_feats_df_test.loc[:,key] = df_test.loc[:,val].mean(axis='columns')\n","\n","        if save_csv:\n","            group_feats_df_train.to_csv(f\"{output_path_prefix}_train.csv\",sep=',',index=False)\n","            group_feats_df_test.to_csv(f\"{output_path_prefix}_test.csv\",sep=',',index=False)\n","        return group_feats_df_train, group_feats_df_test"],"metadata":{"id":"2-Qi9UUSQXV3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Kmeans clustering, grouping, and store features\n"],"metadata":{"id":"LE_tIo_tXDQg"}},{"cell_type":"code","source":["import sklearn\n","from sklearn.cluster import KMeans\n","\n","def kmeans_grouping(df,df_test, output_path_prefix, cluster_number=10, random_state=20, save_csv=True):\n","    \"\"\"\n","    Group and merge training and testing features based on correlation between the dimensions.\n","\n","    Args:\n","        df (Dataframe): training corpus features\n","        df_test (Dataframe): testing corpus features\n","        output_path_prefix (str): prefix to the file path where the output files will be saved.\n","        cluster_number (str): define the number of dimension clusters. Default as 10.\n","        random_state (float): random state to start kmeans clustering. Default as 20.\n","        save_csv (bool): whether to save the output csv files. Default as True.\n","\n","\n","    Returns:\n","        group_feats_df_train (Dataframe): training corpus features after merging\n","        group_feats_df_test (Dataframe): testing corpus features after merging\n","    \"\"\"\n","    no_feats = len(df.columns)-1\n","    X_train = df.iloc[:,:no_feats]\n","    y_train = df.iloc[:,no_feats]\n","\n","    transposed_df = X_train.T\n","\n","    mat = transposed_df.values\n","    km = sklearn.cluster.KMeans(n_clusters=cluster_number,init='k-means++',random_state=random_state)\n","    km.fit(mat)\n","    labels = km.labels_\n","\n","    results = pd.DataFrame([transposed_df.index,labels]).T\n","\n","    label_groups = {}\n","    for i in range(cluster_number):\n","        label_groups[i]=[]\n","\n","\n","    for i in range(len(results.index)):\n","        label_groups[int(results.iloc[i,1])].append(results.iloc[i,0])\n","\n","    updated_groups = {}\n","    dims_included = []\n","    for key,val in label_groups.items():\n","\n","        updated_groups[val[0]] = val\n","        dims_included.extend(val)\n","        dims_included = list(set(dims_included))\n","\n","    new_column_names = list(updated_groups.keys()) + ['Class_label']\n","    group_feats_df_train = df.loc[:,new_column_names]\n","    for key,val in updated_groups.items():\n","        group_feats_df_train.loc[:,key]  = df.loc[:,val].mean(axis='columns')\n","    group_feats_df_test = df_test.loc[:,new_column_names]\n","    for key,val in updated_groups.items():\n","        group_feats_df_test.loc[:,key] = df_test.loc[:,val].mean(axis='columns')\n","\n","    if save_csv:\n","        group_feats_df_train.to_csv(f\"{output_path_prefix}_train.csv\",sep=',',index=False)\n","        group_feats_df_test.to_csv(f\"{output_path_prefix}_test.csv\",sep=',',index=False)\n","    return group_feats_df_train, group_feats_df_test"],"metadata":{"id":"7alZzvl-UhJC"},"execution_count":null,"outputs":[]}]}