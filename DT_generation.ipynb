{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPI5V6UHxbSzRN4MnEWJF6H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Env"],"metadata":{"id":"JetDD2qQ1YSe"}},{"cell_type":"code","source":["!git clone https://github.com/serengil/chefboost.git"],"metadata":{"id":"aCpky7Aq1Zq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install chefboost"],"metadata":{"id":"omrTM25o1gFY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# replace the folders where the package is installed with the github version\n","!rm -r '/usr/local/lib/python3.10/dist-packages/chefboost/'\n","!cp -r '/content/chefboost/chefboost' '/usr/local/lib/python3.10/dist-packages/chefboost'"],"metadata":{"id":"1TQ1DH-Z1hdZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# functions"],"metadata":{"id":"UEYB5ym-2Cky"}},{"cell_type":"markdown","source":["## load precomputed feature"],"metadata":{"id":"we7yCCQ0IgzA"}},{"cell_type":"code","source":["import pandas as pd\n","def load_features(train_path, test_path):\n","    \"\"\"\n","    (Same function in Cluster_feature.ipynb) Load precomputed features/embeddings for training and testing\n","\n","    Args:\n","        train_path (str): where the training corpus features (after dimension reduction) is saved. Each row contains the precomputed features and the ground truth class label for one document.\n","        test_path (str): where the testing corpus features (after dimension reduction) is saved. Each row contains the precomputed features and the ground truth class label for one document.\n","\n","    Returns:\n","        df (Dataframe): training corpus features\n","        df_test (Dataframe): testing corpus features\n","    \"\"\"\n","\n","    df = pd.read_csv(train_path,sep=',')\n","    df['Class_label'] = df['Class_label'].astype(str)\n","\n","    df_test = pd.read_csv(test_path,sep=',')\n","    df_test['Class_label'] = df_test['Class_label'].astype(str)\n","\n","    return df, df_test"],"metadata":{"id":"ZvrSFMf12ETN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DT training and evaluation"],"metadata":{"id":"CVTXWVyhIlV0"}},{"cell_type":"code","source":["import os\n","from chefboost import Chefboost as chef\n","\n","def train_dt(output_folder, train_df, dt_algorithm = 'CART', num_cores = 2, max_depth = 5, enableRandomForest=False, num_of_trees=5):\n","    \"\"\"\n","    Load precomputed features for training and testing\n","\n","    Args:\n","        output_folder: where the  should be saved. Under this folder, the predefined algorithm creates subfolders ./outputs/rules/ to save the rules of the trained decision tree as rules.py, rules.json, model.pkl.\n","        train_df (Dataframe): training corpus features. Each row contains the precomputed features and the ground truth class label for one document (Column name for the class label is supposed to be 'Class_label').\n","        dt_algorithm (str): define the training algorithm for the decision tree. Possible values are 'CART', 'C4.5', 'ID3'. Default is 'CART'.\n","        num_cores (int): number of cpu cores used in parallel during decision training. Default is 2 for running in Google Colab cloud service as the most compatible option.\n","        max_depth (int): maximum depth of the decision tree. Default is 5.\n","\n","    Returns:\n","       model(object): trained decision tree model, an object defined by the chefboost library. Note that the rules of the decision tree are saved as the if-elif-else python statements during the training process in the output folder where the model is saved.\n","    \"\"\"\n","    os.makedirs(output_folder, exist_ok=True)\n","    os.chdir(output_folder)\n","\n","    if enableRandomForest:\n","        config = {'algorithm': dt_algorithm,'num_cores':num_cores,'max_depth':max_depth,'enableRandomForest': enableRandomForest, 'num_of_trees': num_of_trees}\n","    else:\n","        config = {'algorithm': dt_algorithm,'num_cores':num_cores,'max_depth':max_depth}\n","    model = chef.fit(train_df, config = config, target_label = 'Class_label')\n","    chef.save_model(model, \"model.pkl\")\n","    return model"],"metadata":{"id":"IVUFQIgJ3IjK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def evaluate_df(model, df_test):\n","    \"\"\"\n","    Run inference of the trained decision tree on the testing test features and compute the accuracy and f1 score\n","\n","    Args:\n","        model(object): trained decision tree model\n","        df_test (Dataframe): testing corpus features. Each row contains the precomputed features and the ground truth class label for one document (Column name for the class label is supposed to be 'Class_label').\n","\n","    Returns:\n","        acc (float): accuracy of the model\n","        f1 (float): f1 score of the model\n","    \"\"\"\n","    no_feats = len(df_test.columns)-1\n","    instance_no = len(df_test.index)\n","\n","    X_test = df_test.iloc[:,:no_feats]\n","    y_test = df_test.iloc[:,no_feats]\n","\n","    predictions = []\n","    for i in range(instance_no):\n","        prediction = chef.predict(model, X_test.iloc[i])\n","        predictions.append(prediction)\n","\n","    acc = accuracy_score(y_test,predictions)\n","    f1 = f1_score(y_test,predictions)\n","\n","    return acc, f1"],"metadata":{"id":"o6wASxc66Zag","executionInfo":{"status":"ok","timestamp":1719193709731,"user_tz":-600,"elapsed":1660,"user":{"displayName":"Feiqi Cao","userId":"11387377942967144783"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def count_rules(model_py_file_path):\n","    \"\"\"\n","    Compute the number of rules of the trained decision tree\n","\n","    Args:\n","        model_py_file_path(str): path to the python script where trained decision tree model rules are saved as 'rules.py'\n","\n","    Returns:\n","        rule_num (float): number of rules of the given decision tree\n","    \"\"\"\n","    with open(model_py_file_path, 'r') as infile:\n","        content = infile.read()\n","        return_no = content.count('return')\n","        else_no = content.count('else')\n","        rule_num = return_no - else_no\n","    return rule_num"],"metadata":{"id":"_z0DQqRn7qp7"},"execution_count":null,"outputs":[]}]}